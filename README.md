

      

![Image](https://github.com/user-attachments/assets/379b0a15-cecc-4339-a847-fbc40267cb5b)

# Overview

As part of the project, ‘Resume builder’ Rahibur Rahman decided to test a few functionalities of this web application. 

This document serves as high-level test planning document with details on the  scope of the project, test strategy, test schedule and resource requirements,  test deliverables and schedule. 

# Mind Map

![Image](https://github.com/user-attachments/assets/5ee30ca1-387c-417b-8151-5d39cb1e8ce3)

# Scope 

The project scope includes testing the following features of  this web application. 

**Inclusions** 

* Register   
* Login & Logout   
* Home Page   
* Search function  
* Build Resume page  
* View resume page  
* Edit Resume page  
* Download resume functionality  
* Delete Functionality  
* Contact Us Page   
* Real-time mail system  
* About Page  
* Menu Options   
* Footer Options 


  From our understanding, the above functional areas need to be Tested. 


  

  # Test Environments 

  • Windows 10 – Chrome, Firefox and Edge 

  • Mac OS – Safari Browser 

  • Android Mobile OS – Chrome 

  • iPhone Mobile OS \- Safari 


 # Exclusions 

  • All the features except those that are mentioned under ‘Inclusions’ 

  • Any third-party features or Payment gateways  

  • Test Automation

  Test Strategy 

  ‘Rahibur Rahman’ has communicated with the team members and has understood that they need to perform Functional Testing of all the functionalities mentioned in the above  Scope section. 

  As part of Functional Testing, he will follow the below approach for Testing: 

**Step\#1 – Creation of Test Scenarios and Test Cases for the different features in  scope.**  

• He will apply several Test Designing techniques while creating Test Cases  

**Equivalence Class Partition** 

 **Boundary Value Analysis** 

 **Decision Table Testing** 

 **State Transition Testing** 

  **Use Case Testing** 

• He also use our expertise in creating Test Cases by applying the below:

        o Error Guessing 

o Exploratory Testing 

• We prioritise the Test Cases 

**Step\#2 – Our Testing process, when we get an Application for Testing:** 

• Firstly, he will perform Smoke Testing to check whether the different and important functionalities of the application are working. 

• We reject the build, if the Smoke Testing fails and will wait for the stable build before performing in-depth testing of the application functionalities.

 • Once we receive a stable build, which passes Smoke Testing, we perform in depth testing using the Test Cases created. 

• Multiple Test Resources will be testing the same Application on Multiple  Supported Environments simultaneously. 

• We then report the bugs in bug tracking tool and send dev. management the defect found on that day in a status end of the day email. 

• As part of the Testing, we will perform the below types of Testing: 

        **Smoke Testing and Sanity Testing** 

  **Regression Testing and Retesting**  

  **Usability Testing, Functionality & UI Testing**


• We repeat Test Cycles until we get the quality product. 

         **Step\#3 – We will follow the below best practices to make our Testing better:** 

• **Context-Driven Testing** – We will be performing Testing as per the context of the given application. 

• **Shift Left Testing** – We will start testing from the beginning stages of the development itself, instead of waiting for the stable build. 

• **Exploratory Testing** – Using our expertise we will perform Exploratory  Testing, 

       apart from the normal execution of the Test cases.

• **End-to-end Flow Testing** – We will test the end-to-end scenario which involves multiple functionalities to simulate the end user flows. 

Defect Reporting Procedure: 

During the test execution – 

• Any deviation from expected behaviour by the application will be noted. If  it can’t be reported as a defect, it’d be reported as an observation/issue or  posed as a question. 

• Any usability issues will also be reported. 

• After discovery of a defect, it will be retested to verify reproducibility of  the defect. Screenshots with steps to reproduce are documented. 

• Every day, at the end of the test execution, defects encountered will be sent along with the observations. 

**Note:** 

• Defects will be documented in Excel. 

• Test scenarios and Test cases will be documented in an Excel document. 

# Roles/Responsibilities

| Name  | Role  | Responsibilities |
| ----- | ----- | ----- |
| Rahibur Rahman  | Software Tester  | ✓ Create the Test Plan  ✓ Interact with the application, create  and execute the test cases  ✓ Report defects   |

                    Test Schedule 

Following is the test schedule planned for the project – 

| Task  | Time Duration |
| ----- | :---: |
| ▪ Creating a Test Plan  | 1 March 2025  |
| ▪ Test Case Creation  | 2 March 2025 \- 4 March 2025 |
| ▪ Test Case Execution  | 5 March 2025 \- 7 March 2025 |
| ▪ Summary Reports Submission  | 7 March 2025 |

            Entry and Exit Criteria 

Below are the entry and exit criteria for every phase of the Software Testing Life  Cycle: 

**Requirement Analysis** 

**Entry Criteria:** 

• Once the testing team receives the Requirements Documents or details  about the Project 

**Exit Criteria:** 

• List of Requirements is explored and understood by the Testing team

 • Doubts are cleared 

**Test Planning**

**Entry Criteria:** 

• Testable Requirements derived from the given Requirements Documents  or Project details 

• Doubts are cleared 

**Exit Criteria:** 

• Test Plan document (includes Test Strategy) is signed-off by the Client  **Test Designing** 

**Entry Criteria:** 

• Test Plan Document is signed-off by the Client 

**Exit Criteria:** 

• Test Scenarios and Test Cases Documents are signed-off by the Client **Test Execution** 

**Entry Criteria:** 

• Test Scenarios and Test Cases Documents are signed-off by the Client • Application is ready for Testing 

**Exit Criteria:** 

• Test Case Reports, Defect Reports are ready 

**Test Closure** 

**Entry Criteria:** 

• Test Case Reports, Defect Reports are ready 

**Exit Criteria:** 

• Test Summary Reports 

# Suspension and Resumption Criteria 

Based on the Client's decision, we will suspend and resume the Project. We will ramp up and ramp down the resources as per Client needs. 

Tools 

The following are the list of Tools we will be using in this Project: 

• XYZ Bug Tracking Tool 

• Mind map Tool  

• Snipping Screenshot Tool 

• Word and Excel documents 

# Risks and Mitigations 

The following are the list of risks possible and the ways to mitigate them: 

**Risk:** Non-Availability of a Resource 

**Mitigation:** Backup Resource Planning 

**Risk:** Build URL is not working 

**Mitigation:** Resources will work on other tasks 

**Risk:** Less time for Testing 

       **Mitigation:** Ramp up the resources based on the Client's needs dynamically 

Approvals 

The team will send different types of documents for Client Approval like below: 

• Test Plan 

• Test Scenarios 

• Test Cases 

• Reports 

Testing will only continue to the next steps once these approvals are done.

![Image](https://github.com/user-attachments/assets/87fa09d9-745d-4b3f-b597-05f9f6846a60)

![Image](https://github.com/user-attachments/assets/72e0820a-2461-413e-aa9e-b337045eb4c1)

![Image](https://github.com/user-attachments/assets/38e5113b-7102-4c88-829c-d1fbe9dd3e57)







